import json
import os
import base64
import tempfile
from datetime import datetime

from connections import Connections
from exporters.pdf_exporter import PdfExporter
from exporters.docx_exporter import DocxExporter
from exporters.ppt_exporter import PptExporter
from utils.exceptions import exception_handler, ExportFormatError
from utils.logger import get_logger

logger = get_logger("index")

EXPORTER_MAP = {
    "docx": DocxExporter,
    "pdf": PdfExporter,
    "ppt": PptExporter,
}

@exception_handler
def lambda_handler(event, context):
    logger.info(f"Received event: {event}")
    
    try:
        body = json.loads(event["body"])
        company_info = body["company_info"]
        raw_analysis = body["analysis"]
        file_format = body["format"].lower()
        session_id = body["session_id"]

        # è™•ç†åœ–è¡¨æ•¸æ“š
        charts_data = body.get("charts_data", {})
        logger.info(f"æ¥æ”¶åˆ°åœ–è¡¨æ•¸æ“šé é¢: {list(charts_data.keys())}")

        # è™•ç†åœ–è¡¨ä½ç½®ä¿¡æ¯
        charts_position_info = body.get("charts_position_info", {})
        logger.info(f"æ¥æ”¶åˆ°åœ–è¡¨ä½ç½®ä¿¡æ¯é é¢: {list(charts_position_info.keys())}")
        
        # å°‡ base64 è½‰æ›ç‚º bytes
        # é€™æ¨£é¿å…äº† invoke-lambda è¿”å›ä¸å¯åºåˆ—åŒ–çš„ bytes æ•¸æ“š
        processed_charts_data = {}
        for page_name, charts_list in charts_data.items():
            processed_charts_data[page_name] = []
            
            for chart in charts_list:
                # ç›´æ¥ä¿æŒåŸæœ‰æ ¼å¼ï¼Œä¸åšé¡å¤–è™•ç†
                processed_chart = chart.copy()
                
                # åªåšé©—è­‰ï¼Œä¸è½‰æ›
                img_static_b64 = chart.get("img_static_b64")
                if img_static_b64:
                    logger.info(f"âœ… åœ–è¡¨ {chart.get('title_text')} åŒ…å«æœ‰æ•ˆçš„ base64 æ•¸æ“š")
                else:
                    logger.warning(f"âš ï¸ åœ–è¡¨ {chart.get('title_text')} ç¼ºå°‘ img_static_b64 æ•¸æ“š")
                
                processed_charts_data[page_name].append(processed_chart)
        
        logger.info(f"ğŸ“Š åœ–è¡¨æ•¸æ“šè™•ç†å®Œæˆï¼Œç¸½è¨ˆ {sum(len(charts) for charts in processed_charts_data.values())} å€‹åœ–è¡¨")

        # æª¢æŸ¥æª”æ¡ˆæ ¼å¼æ˜¯å¦æ”¯æ´
        if file_format not in EXPORTER_MAP:
            logger.error(f"ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼: {file_format}")
            raise ExportFormatError(f"ä¸æ”¯æ´çš„åŒ¯å‡ºæ ¼å¼: {file_format}")

        # æ•´ç†åˆ†æè³‡æ–™çµæ§‹
        analysis = {
            sec: {"å…§å®¹": (txt.strip() or "ï¼ˆæœªæä¾›å…§å®¹ï¼‰")}
            for sec, txt in raw_analysis.items()
        }

        # ç”Ÿæˆæª”æ¡ˆåç¨±å‰ç¶´
        prefix = (
            f"{company_info.get('å“ç‰Œåç¨±', 'å ±å‘Š')}_"
            f"{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        )

        # ä½¿ç”¨è‡¨æ™‚ç›®éŒ„è™•ç†æª”æ¡ˆ
        with tempfile.TemporaryDirectory() as tmpdir:
            file_path = os.path.join(tmpdir, f"{prefix}.{file_format}")

            # é¸æ“‡å°æ‡‰çš„åŒ¯å‡ºå™¨
            exporter_cls = EXPORTER_MAP[file_format]
            
            # æ ¹æ“šæª”æ¡ˆæ ¼å¼æ±ºå®šæ˜¯å¦å‚³å…¥åœ–è¡¨æ•¸æ“š
            if file_format == "docx":
                # åªæœ‰ Word æ ¼å¼éœ€è¦åœ–è¡¨æ•¸æ“š
                exporter = exporter_cls(
                    analysis, 
                    company_info, 
                    processed_charts_data,
                    charts_position_info
                )
                logger.info(f"å»ºç«‹ DOCX åŒ¯å‡ºå™¨ï¼ŒåŒ…å« {sum(len(v) for v in processed_charts_data.values())} å€‹åœ–è¡¨")
                logger.info(f"åœ–è¡¨ä½ç½®ä¿¡æ¯: {sum(len(v) for v in charts_position_info.values())} å€‹ä½ç½®è¨˜éŒ„")
            else:
                # PDF å’Œ PPT æš«ä¸æ”¯æ´åœ–è¡¨æ’å…¥
                exporter = exporter_cls(analysis, company_info)
                logger.info(f"å»ºç«‹ {file_format.upper()} åŒ¯å‡ºå™¨ï¼ˆä¸åŒ…å«åœ–è¡¨ï¼‰")
                
            # åŸ·è¡Œæª”æ¡ˆåŒ¯å‡º
            logger.info(f"é–‹å§‹åŒ¯å‡ºæª”æ¡ˆ: {file_path}")
            exporter.export(file_path)
            
            # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦æˆåŠŸç”Ÿæˆ
            if not os.path.exists(file_path):
                raise Exception(f"æª”æ¡ˆç”Ÿæˆå¤±æ•—: {file_path}")
            
            file_size = os.path.getsize(file_path)
            logger.info(f"æª”æ¡ˆç”ŸæˆæˆåŠŸ: {file_path}, å¤§å°: {file_size} bytes")

            # ä¸Šå‚³è‡³ S3
            s3_key = f"exports/{session_id}/{prefix}.{file_format}"
            logger.info(f"ä¸Šå‚³æª”æ¡ˆè‡³ S3: {s3_key}")
            
            Connections.s3_client().upload_file(
                file_path, Connections.s3_bucket_name, s3_key
            )

            # è®€å–æª”æ¡ˆä¸¦è½‰æ›ç‚º base64
            with open(file_path, "rb") as f:
                file_content = f.read()
                encoded = base64.b64encode(file_content).decode("utf-8")

            logger.info(f"æª”æ¡ˆåŒ¯å‡ºå®Œæˆä¸¦ä¸Šå‚³è‡³ S3: {s3_key}")
            logger.info(f"æª”æ¡ˆå¤§å°: {len(file_content)} bytes, Base64 å¤§å°: {len(encoded)} å­—ç¬¦")

            # è¿”å›æˆåŠŸéŸ¿æ‡‰
            return {
                "statusCode": 200,
                "body": json.dumps({
                    "message": "åŒ¯å‡ºæˆåŠŸ",
                    "download_path": f"s3://{Connections.s3_bucket_name}/{s3_key}",
                    "filename": f"{prefix}.{file_format}",
                    "filedata": encoded,
                    "file_size": len(file_content),
                    "charts_count": sum(len(v) for v in processed_charts_data.values()) if file_format == "docx" else 0
                }, ensure_ascii=False),
            }
            
    except json.JSONDecodeError as json_err:
        logger.error(f"JSON è§£æéŒ¯èª¤: {json_err}")
        return {
            "statusCode": 400,
            "body": json.dumps({
                "error": "è«‹æ±‚æ ¼å¼éŒ¯èª¤",
                "message": f"JSON è§£æå¤±æ•—: {str(json_err)}"
            }, ensure_ascii=False)
        }
        
    except ExportFormatError as format_err:
        logger.error(f"æ ¼å¼éŒ¯èª¤: {format_err}")
        return {
            "statusCode": 400,
            "body": json.dumps({
                "error": "ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼",
                "message": str(format_err)
            }, ensure_ascii=False)
        }
        
    except Exception as general_err:
        logger.error(f"åŒ¯å‡ºéç¨‹ç™¼ç”ŸéŒ¯èª¤: {general_err}", exc_info=True)
        return {
            "statusCode": 500,
            "body": json.dumps({
                "error": "æª”æ¡ˆåŒ¯å‡ºå¤±æ•—",
                "message": f"ç³»çµ±éŒ¯èª¤: {str(general_err)}"
            }, ensure_ascii=False)
        }