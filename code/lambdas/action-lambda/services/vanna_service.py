"""
vanna_service.py - Vannaæœå‹™å°è£ï¼Œè™•ç†èˆ‡OpenSearchå’ŒAthenaçš„äº¤äº’
"""
import os
import json
import time
import uuid
import datetime
import traceback
from typing import Any, Dict, List, Callable, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError
from functools import wraps
import pandas as pd
import plotly.io as pio

from vanna.opensearch import OpenSearch_VectorStore
from vanna.bedrock import Bedrock_Converse

from utils.logger import setup_logger
from utils.exceptions import ValidationError, ExternalAPIError
from utils.temp_llm import claude_call, parse_claude_json
from models.vanna import CompanyInfo, OutputFormat, QueryItem
from services.connections import Connections

from concurrent.futures import TimeoutError as FuturesTimeoutError, wait, FIRST_COMPLETED
import base64
import mimetypes

# æŒ‰ç…§å®˜æ–¹åŠ å…¥ https://pypi.org/project/kaleido/
# kaleido.get_chrome_sync()

logger = setup_logger(__name__)

# è¨­å®šè¶…æ™‚æ™‚é–“ (ç§’)
CHART_GENERATION_TIMEOUT = 60

# å–®å¼µåœ–å¹³å‡æœ€å¤šèŠ±å¤šä¹… (ç§’)ï¼›
AVG_CHART_SEC = 45
# æ•´æ‰¹ä»»å‹™æœ€å°‘ç­‰å¾…å¤šä¹… (ç§’)ï¼›é¿å…å°é‡ä»»å‹™æ™‚ timeout å¤ªçŸ­
MIN_PARALLEL_WAIT = 120

# S3 put_object æœ€å¤šé‡è©¦æ¬¡æ•¸ï¼ˆå«ç¬¬ä¸€æ¬¡ = MAX_RETRY + 1ï¼‰
S3_MAX_RETRY = 2
# æ¯æ¬¡é‡è©¦å‰éœé»˜ç§’æ•¸
S3_RETRY_SLEEP = 1.5




class VannaService(OpenSearch_VectorStore, Bedrock_Converse):
    """
    Vannaæœå‹™é¡ï¼Œæ•´åˆOpenSearchå‘é‡å„²å­˜å’ŒBedrockå°è©±èƒ½åŠ›ï¼Œä»¥åŠAthenaé€£æ¥
    """
    
    def __init__(self):
        """åˆå§‹åŒ–VannaServiceï¼Œé€£æ¥OpenSearchå’ŒBedrock"""
        # åˆå§‹åŒ–é€£æ¥
        self.conn = Connections()
        self.env = self.conn.env
        
        # è¨­å®šç´¢å¼•åç¨±
        self.document_index = self.env.OS_DOC_INDEX
        self.ddl_index = self.env.OS_DDL_INDEX
        self.question_sql_index = self.env.OS_QSQL_INDEX
        self.s3_bucket = self.env.OUTPUT_S3_BUCKET
        
        # ç²å–Openseachä¸»æ©Ÿ
        os_host = os.getenv("OPENSEARCH_HOST", "")
        if not os_host:
            raise ValidationError("OpenSearch host not specified in environment variables")
        
        os_host = os_host.removeprefix("https://")
        
        # ä½¿ç”¨Connectionså‰µå»ºBedrockå®¢æˆ¶ç«¯
        bedrock_client = self.conn.bedrock_client()
        
        # åˆå§‹åŒ–Bedrockæœƒè©±
        Bedrock_Converse.__init__(
            self,
            client=bedrock_client,
            config={
                "modelId": "us.anthropic.claude-3-7-sonnet-20250219-v1:0",
                "temperature": float(0.0),
                "max_tokens": int(5000),
            },
        )
        
        # ä½¿ç”¨Connectionså‰µå»ºOpenSearchå®¢æˆ¶ç«¯
        self.opensearch_client = self.conn.opensearch_client(os_host)
        
        # é©—è­‰ç´¢å¼•å·²å­˜åœ¨
        self._verify_indices()
        
        # è¨­å®šSQLé‹è¡Œå‡½æ•¸åˆå§‹ç‹€æ…‹
        self.run_sql_is_set = False
        self.dialect = None

    def safe_execute(self, func, *args, **kwargs):
        """å®‰å…¨åŸ·è¡Œå‡½æ•¸ï¼Œæ•ç²ä¸¦è¨˜éŒ„ç•°å¸¸"""
        try:
            return func(*args, **kwargs), None
        except Exception as e:
            logger.error(f"å®‰å…¨åŸ·è¡Œå¤±æ•—: {str(e)}")
            logger.error(f"å †ç–Šè¿½è¹¤: {traceback.format_exc()}")
            return None, str(e)

    def gen_ts_random_id(self) -> str:
        """ç”Ÿæˆå¸¶æ™‚é–“æˆ³çš„éš¨æ©Ÿ ID"""
        try:
            ts = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
            rand_suffix = str(uuid.uuid4().int)[:8]
            return f"{ts}_{rand_suffix}"
        except Exception as e:
            logger.warning(f"ç”Ÿæˆ ID å¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ: {str(e)}")
            return f"fallback_{int(time.time())}"

    def extract_company_info(
        self,
        input_text: str,
        info: CompanyInfo
    ) -> CompanyInfo:
        """æå–å…¬å¸/å“ç‰Œ/ç”¢å“/é¡åˆ¥/ç›®æ¨™æ¨™é¡Œè³‡è¨Š"""

        try:
            # 1. æ‰€æœ‰æ¬„ä½å·²é½Šï¼Œç›´æ¥å›å‚³åŸ info
            if all([
                info.company,
                info.brand,
                info.product,
                info.product_category,
                info.target_title
            ]):
                return info

            # 2. ä½¿ç”¨ Claude è£œå…¨ç¼ºå¤±æ¬„ä½
            system_prompt = (
                "You are a JSON-extraction assistant.\n"
                "From the user's message, identify company, brand, product, "
                "product_category, and target_title.\n"
                "Return one minified JSON exactly like "
                '{"company":"","brand":"","product":"","product_category":"","target_title":""} '
                "with missing values as empty strings. No extra text."
            )

            logger.info("æ­£åœ¨ä½¿ç”¨ Claude æå–å…¬å¸è³‡è¨Š")
            raw_json, error = self.safe_execute(claude_call, system_prompt, input_text)

            if error:
                logger.warning(f"Claude å‘¼å«å¤±æ•—: {error}")
                return info

            try:
                parsed = json.loads(raw_json)
                parsed = parse_claude_json(parsed)  # å¯é¸çš„æ ¼å¼æ¸…ç†å‡½æ•¸
            except (json.JSONDecodeError, ValueError) as e:
                logger.warning(f"è§£æ Claude å›æ‡‰å¤±æ•—: {str(e)}")
                return info

            # åˆä½µåŸå§‹èˆ‡ Claude çš„è³‡è¨Šï¼ˆClaude åƒ…è£œç¼ºæ¬„ä½ï¼‰
            return CompanyInfo(
                company=info.company or parsed.get("company", ""),
                brand=info.brand or parsed.get("brand", ""),
                product=info.product or parsed.get("product", ""),
                product_category=info.product_category or parsed.get("product_category", ""),
                target_title=info.target_title or parsed.get("target_title", "")
            )

        except Exception as e:
            logger.error(f"æå–å…¬å¸è³‡è¨Šæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return info

    def setup_training(self) -> bool:
        """è¨­å®š Vanna è¨“ç·´è³‡æ–™"""
        try:
            # å–å¾— Athena æŸ¥è©¢åŸ·è¡Œå™¨
            run_sql, error = self.safe_execute(self.conn.athena_query_runner)
            if error:
                logger.error(f"å–å¾— Athena æŸ¥è©¢åŸ·è¡Œå™¨å¤±æ•—: {error}")
                return False
            
            # è¨­å®š Athena é€£æ¥
            self.set_athena_connection(run_sql)
            
            # ç²å– schema è³‡è¨Š
            schema_sql = "SELECT * FROM information_schema.columns WHERE table_schema = 'default' AND table_name = 'invoice_data_invdate'"
            df_information_schema, error = self.safe_execute(self.run_sql, schema_sql)
            
            if error:
                logger.error(f"ç²å– schema è³‡è¨Šå¤±æ•—: {error}")
                return False
            
            if df_information_schema is None:
                logger.error("schema è³‡è¨Šç‚ºç©º")
                return False
            
            logger.info(f"æˆåŠŸç²å– schema è³‡è¨Š: {df_information_schema}")
            
            # ç²å–è¨“ç·´è¨ˆåŠƒ
            plan, error = self.safe_execute(self.get_training_plan_generic, df_information_schema)
            if error:
                logger.error(f"ç²å–è¨“ç·´è¨ˆåŠƒå¤±æ•—: {error}")
                return False
            
            logger.info(f"æˆåŠŸç²å–è¨“ç·´è¨ˆåŠƒ: {plan}")
            
            # åŸ·è¡Œè¨“ç·´
            return self._execute_training_tasks(plan)
            
        except Exception as e:
            logger.error(f"è¨­å®š Vanna è¨“ç·´æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return False

    def _execute_training_tasks(self, plan) -> bool:
        """åŸ·è¡Œè¨“ç·´ä»»å‹™"""
        training_tasks = [
            (self.train, {"plan": plan}),
            (self.train, {
                "documentation": """
                You have to give an AWS Athena SQL for each question.Table name is  "default"."invoice_data_invdate".Each query needs to specify invDate. If invDate is specified, the default is the last 14 days.This is an invoice table storing each customer's invoice data. Below are the columns and their descriptions. 
                Columns: 
                inv_num (invoice number),
                aaid (Android device id),
                idfa (iOS device id),
                vid (user_id),
                invDate (yyyy-mm-dd,date, invoice issue date, partitioned columns), 
                invTime (time, invoice issue time), 
                sellerName (merchant official name), 
                storeName (merchant nickname or store alias), 
                sellerAddress (merchant address in half-width characters), 
                description (product name on invoice), 
                unit_Price (float, price per product), 
                quantity (float, purchased quantity), 
                birthday (YYYY-MM-DD, inferred user birthday),
                gender (inferred user gender),
                amount (integer, total invoice amount)
                """,
                "plan": plan
            })
        ]
        
        # æ·»åŠ ç¯„ä¾‹è¨“ç·´
        training_examples = self._get_training_examples(plan)
        training_tasks.extend([(self.train, example) for example in training_examples])
        
        # åŸ·è¡Œæ‰€æœ‰è¨“ç·´ä»»å‹™
        success_count = 0
        for task_func, task_kwargs in training_tasks:
            _, error = self.safe_execute(task_func, **task_kwargs)
            if error:
                logger.warning(f"è¨“ç·´ä»»å‹™å¤±æ•—: {error}")
            else:
                success_count += 1
        
        logger.info(f"å®Œæˆè¨“ç·´ï¼ŒæˆåŠŸ {success_count}/{len(training_tasks)} å€‹ä»»å‹™")
        return success_count > 0

    def _get_training_examples(self, plan) -> List[Dict]:
        """å–å¾—è¨“ç·´ç¯„ä¾‹"""
        return [
            {
                "question": "4æœˆä»½éŠ·å”®æ•¸å‰10åçš„å•†å“",
                "sql": """
                SELECT
                    description AS product_name,
                    SUM(quantity) AS total_sales_counts
                FROM
                    "default"."invoice_data_invdate"
                WHERE
                    invDate BETWEEN '2025-04-01' AND '2025-04-30'
                GROUP BY
                    description
                ORDER BY
                    total_sales_counts DESC
                LIMIT 10;
                """,
                "plan": plan
            },
            {
                "question": "4æœˆä»½éŠ·å”®é¡å‰10åçš„å•†å“",
                "sql": """
                SELECT
                    description AS product_name,
                    SUM(unit_Price * quantity) AS total_sales_amount
                FROM
                    "default"."invoice_data_invdate"
                WHERE
                    invDate BETWEEN '2025-04-01' AND '2025-04-30'
                GROUP BY
                    description
                ORDER BY
                    total_sales_amount DESC
                LIMIT 10;
                """,
                "plan": plan
            },
            {
                "question": "4æœˆä»½ storeName éŠ·å”®ä½”æ¯”",
                "sql": """
                WITH total_sales AS (
                    SELECT 
                        SUM(amount) AS total_amount
                    FROM 
                        "default"."invoice_data_invdate"
                    WHERE 
                        invDate BETWEEN '2025-04-01' AND '2025-04-30'
                )
                SELECT 
                    storeName,
                    SUM(amount) AS store_total_sales,
                    ROUND((SUM(amount) * 100.0) / (SELECT total_amount FROM total_sales), 2) AS sales_percentage
                FROM 
                    "default"."invoice_data_invdate"
                WHERE 
                    invDate BETWEEN '2025-04-01' AND '2025-04-30'
                GROUP BY 
                    storeName
                ORDER BY 
                    sales_percentage DESC;
                """,
                "plan": plan
            },
            {
                "question": "4æœˆä»½æ€§åˆ¥çš„éŠ·å”®é¡å’Œå¹³å‡ç™¼ç¥¨é‡‘é¡",
                "sql": """
                WITH distinct_invoices AS (
                    SELECT
                        gender,
                        inv_num,
                        MAX(amount) AS invoice_amount
                    FROM
                        "default"."invoice_data_invdate"
                    WHERE
                        invDate BETWEEN '2025-04-01' AND '2025-04-30'
                    GROUP BY
                        gender, inv_num
                )
                SELECT
                    gender,
                    SUM(invoice_amount) AS total_sales_amount,
                    ROUND(AVG(invoice_amount), 2) AS avg_invoice_amount,
                    COUNT(*) AS invoice_count
                FROM
                    distinct_invoices
                GROUP BY
                    gender
                ORDER BY
                    total_sales_amount DESC;
                """,
                "plan": plan
            }
        ]

    def plotly_to_html(self, fig) -> Optional[bytes]:
        """
        å°‡ Plotly åœ–è¡¨è½‰ç‚º HTML bytes  
        - åªè² è²¬ã€è½‰æ›ã€ï¼Œä¸ä¸Šå‚³ï¼Œç¬¦åˆ SRP
        """
        try:
            if fig is None:
                return None

            logger.info("Converting figure to HTML")
            html_str = pio.to_html(
                fig,
                include_plotlyjs="cdn",
                full_html=True,
                auto_play=False,
            )
            return html_str.encode("utf-8")
        except Exception as e:
            logger.error(f"Error generating HTML: {e}")
            return None

    def generate_single_chart(
        self,
        question: str,
        uu_id_str: str,
        index: int,
        target_path: str = "",
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆå–®ä¸€åœ–è¡¨  
        1. å…ˆå˜—è©¦ Kaleido è½‰ PNGï¼ŒæˆåŠŸâ†’ä¸Šå‚³ S3ï¼ˆ.pngï¼‰  
        2. Kaleido å¤±æ•—å‰‡è¼¸å‡ºäº’å‹• HTML â†’ ä¸Šå‚³ S3ï¼ˆ.htmlï¼‰  
        3. å›å‚³çµ±ä¸€ç‚º S3 public URL
        """

        S3_MAX_RETRY = globals().get("S3_MAX_RETRY", 3)
        S3_RETRY_SLEEP = globals().get("S3_RETRY_SLEEP", 1.0)

        def _upload_to_s3(key: str, data: bytes) -> str:
            """å…§éƒ¨å°å·¥å…·ï¼šè‡ªå‹•é‡è©¦ä¸Šå‚³ä¸¦å›å‚³ public URL"""
            content_type, _ = mimetypes.guess_type(key)
            content_type = content_type or "application/octet-stream"
            s3_client = self.conn.s3_client_fbmapping()

            last_err = None
            for attempt in range(S3_MAX_RETRY + 1):
                try:
                    s3_client.put_object(
                        Bucket=self.s3_bucket,
                        Key=key,
                        Body=data,
                        ContentType=content_type,
                    )
                    url = f"https://{self.s3_bucket}.s3.amazonaws.com/{key}"
                    logger.info(f"Uploaded to S3 ({attempt+1}/{S3_MAX_RETRY+1}): {key}")
                    return url
                except Exception as exc:                 # noqa: BLE001
                    last_err = exc
                    logger.warning(f"S3 put_object å¤±æ•— ({attempt+1}): {exc}")
                    time.sleep(S3_RETRY_SLEEP)

            raise RuntimeError(f"S3 ä¸Šå‚³å¤±æ•— ({S3_MAX_RETRY+1} attempts): {last_err}")

        try:
            logger.info(f"ğŸ“ˆ ç”¢ç”Ÿåœ–è¡¨ {index}: {question[:120]}â€¦")

            # ---------- 1. å–å¾— (df, sql, fig) ----------
            result, err = self.safe_execute(
                self.ask, 
                question=question.strip(), 
                allow_llm_to_see_data=True,
                auto_train= False,
            )
            print(f"result: {result}")
            if err or not result or len(result) < 3:
                msg = err or "ç„¡æœ‰æ•ˆçµæœ"
                logger.error(f"Vanna å›å‚³éŒ¯èª¤ / æ ¼å¼ä¸æ­£ç¢º: {msg}")
                return {"title_text": f"éŒ¯èª¤: {question[:30]}...", "img_html": None, "error": msg}

            fig = result[2]
            print(f"figæ˜¯: {fig}")
            title_text = fig.layout.title.text if fig and fig.layout.title else f"åœ–è¡¨ {index+1}"

            # ---------- 2. ç¾åŒ– layout ----------
            if fig:
                title_font_family = "Noto Sans CJK TC Medium, Noto Sans CJK TC, sans-serif"
                regular_font_family = "Noto Sans CJK TC Regular, Noto Sans CJK TC, sans-serif"
                title_size_px = int(14 * 1.333)
                label_size_px = int(9 * 1.333)
                fig.update_layout(
                    margin=dict(l=40, r=20, t=60, b=120),
                    xaxis_tickangle=-45,
                    autosize=True,
                    title=dict(
                        font=dict(
                            family=title_font_family,
                            size=title_size_px,
                            color="black"
                        ),
                        x=0.5,
                        xanchor='center'
                    ),
                    font=dict(
                        family=regular_font_family,
                        size= label_size_px,
                        color="black"
                    ),

                    xaxis=dict(
                        title_font=dict(
                            family=regular_font_family,
                            size=label_size_px,
                        ),
                        tickfont=dict(
                            family=regular_font_family,
                            size=label_size_px,
                        )
                    ),
                    yaxis=dict(
                        title_font=dict(
                            family=regular_font_family,
                            size=label_size_px,
                        ),
                        tickfont=dict(
                            family=regular_font_family,
                            size=label_size_px,
                        )
                    ),
                    legend=dict(
                        font=dict(
                            family=regular_font_family,
                            size= label_size_px
                        ),
                        bgcolor="rgba(255, 255, 255, 0.8)",
                        bordercolor="rgba(0, 0, 0, 0.2)",
                        borderwidth=1
                    ),

                    plot_bgcolor='white',
                    paper_bgcolor='white'
                )
                for trace in fig.data:
                    if hasattr(trace, 'textfont'):
                        trace.textfont = dict(
                            family=regular_font_family,
                            size=label_size_px,
                            color="black"
                        )
                    if hasattr(trace, 'insidetextfont'):
                        trace.insidetextfont = dict(
                            family=regular_font_family,
                            size=label_size_px,
                            color="white"
                        )
                    if hasattr(trace, 'outsidetextfont'):
                        trace.outsidetextfont = dict(
                            family=regular_font_family,
                            size=label_size_px,
                            color="black"
                        )
            img_url: Optional[str] = None


            # ---------- 3. å˜—è©¦ PNG ----------
            if fig is not None:
                try:
                    png_bytes = fig.to_image(format="png", width=1200, height=800, scale=2)
                    key = f"vanna/{uu_id_str}/fig_{index}.png"
                    img_url = _upload_to_s3(key, png_bytes)
                    logger.info(f"âœ… PNG å®Œæˆä¸¦ä¸Šå‚³ ({len(png_bytes)} bytes)")
                except Exception as e:                   # noqa: BLE001
                    logger.warning(f"Kaleido ç”¢ç”Ÿ PNG å¤±æ•—ï¼š{e}")

            # ---------- 4. é€€å› HTML ----------
            if img_url is None and fig is not None:
                html_bytes = self.plotly_to_html(fig)
                if html_bytes:
                    key = f"vanna/{uu_id_str}/fig_{index}.html"
                    try:
                        img_url = _upload_to_s3(key, html_bytes)
                        logger.info("âœ… HTML ä¸Šå‚³å®Œæˆ")
                    except Exception as e:               # noqa: BLE001
                        logger.error(f"S3 ä¸Šå‚³ HTML å¤±æ•—: {e}")

            # ---------- 5. çµ„è£å›å‚³ ----------
            vanna_result = {
                "chart_id": uuid.uuid4().hex[:8],
                "title_text": title_text,
                "img_html": img_url,          # S3 public URL æˆ– None
                "question": question,
                "target_path": target_path,
            }
            logger.info(f"ğŸ‰ åœ–è¡¨ {index} å®Œæˆï¼ˆ{'PNG' if img_url and img_url.endswith('.png') else 'HTML'}ï¼‰")
            return vanna_result

        except Exception as e:                             # noqa: BLE001
            logger.error(f"ç”Ÿæˆåœ–è¡¨ {index} æœªé æœŸéŒ¯èª¤: {e}", exc_info=True)
            return {"title_text": f"éŒ¯èª¤: {question[:30]}...", "img_html": None, "error": str(e)}


    def generate_charts_parallel(
        self,
        sql_queries: List[QueryItem],
        uu_id_str: str,
    ) -> Tuple[Dict[str, Any], int]:
        """
        ä¸¦è¡Œç”¢ç”Ÿå¤šå¼µåœ–ï¼ˆå‹•æ…‹ timeoutï¼Œä¸å› å–®ä¸€æ…¢ä»»å‹™æ‹–ç´¯æ•´æ‰¹ï¼‰
        """
        MIN_PARALLEL_WAIT = globals().get("MIN_PARALLEL_WAIT", 30)   # s
        AVG_CHART_SEC = globals().get("AVG_CHART_SEC",    20)   # s/åœ–

        results: Dict[str, Any] = {}
        success_cnt = 0

        total_timeout = max(MIN_PARALLEL_WAIT, AVG_CHART_SEC * len(sql_queries))
        logger.info(f"[Parallel] {len(sql_queries)} charts | timeout={total_timeout:.1f}s")

        start_ts = time.time()
        with ThreadPoolExecutor(max_workers=3) as executor:
            future_to_key = {
                executor.submit(
                    self.generate_single_chart,
                    q["question"],
                    uu_id_str,
                    i,
                    q["path"],
                ): f"{q['title']}__{i}"
                for i, q in enumerate(sql_queries)
            }

            done, not_done = wait(future_to_key.keys(), timeout=total_timeout, return_when=FIRST_COMPLETED)

            # å·²å®Œæˆ
            for fut in done:
                key = future_to_key[fut]
                try:
                    res = fut.result()
                    results[key] = res
                    if res.get("img_html"):
                        success_cnt += 1
                except Exception as e:  # noqa: BLE001
                    logger.error(f"ä»»å‹™ {key} å¤±æ•—: {e}")
                    results[key] = {"title_text": f"ä»»å‹™å¤±æ•—: {key}", "img_html": None, "error": str(e)}

            # å°šæœªå®Œæˆ
            for fut in not_done:
                key = future_to_key[fut]
                remaining = total_timeout - (time.time() - start_ts)
                if remaining <= 0:
                    fut.cancel()
                    results[key] = {"title_text": f"ä»»å‹™è¶…æ™‚: {key}", "img_html": None, "error": "åŸ·è¡Œè¶…æ™‚"}
                    logger.warning(f"ä»»å‹™ {key} è¶…æ™‚ (no remaining time)")
                    continue
                try:
                    res = fut.result(timeout=remaining)
                    results[key] = res
                    if res.get("img_html"):
                        success_cnt += 1
                except FuturesTimeoutError:
                    fut.cancel()
                    results[key] = {"title_text": f"ä»»å‹™è¶…æ™‚: {key}", "img_html": None, "error": "åŸ·è¡Œè¶…æ™‚"}
                    logger.warning(f"ä»»å‹™ {key} è¶…æ™‚")
                except Exception as e:  # noqa: BLE001
                    logger.error(f"ä»»å‹™ {key} å¤±æ•—: {e}")
                    results[key] = {"title_text": f"ä»»å‹™å¤±æ•—: {key}", "img_html": None, "error": str(e)}

        return results, success_cnt


    def collect_sql_queries(self, output_format: OutputFormat) -> List[QueryItem]:
        """
        èµ°è¨ª output_format å·¢ç‹€çµæ§‹ï¼Œæ”¶é›†æ‰€æœ‰ã€Œéç©ºç™½ã€çš„ sql_textã€‚

        - `sql_text` å¯èƒ½æ˜¯ str æˆ– list[str]ï¼Œä¸€å¾‹è½‰æˆ list è™•ç†
        - è‡ªå‹•æ’é™¤å®Œå…¨ç‚ºç©ºç™½çš„é …ç›®ï¼ˆå¦‚ "" æˆ– "   "ï¼‰
        - é‡é»ï¼šå¿½ç•¥æœ€å¤–å±¤ã€Œä¸»é¡Œåç¨±ã€é‚£ä¸€å±¤ï¼Œè®“ path
        èˆ‡ `_build_path_to_key()` ç”¢ç”Ÿçš„ key å°é½Š
        """
        queries: List[QueryItem] = []

        def traverse(node: Any, path: str = "", is_topic_level: bool = False) -> None:
            """
            node: ç›®å‰èµ°è¨ªåˆ°çš„ç¯€é» (dict / å…¶ä»–)
            path: ç›®å‰ç¯€é»åœ¨æ•´æ£µæ¨¹ä¸­çš„è·¯å¾‘å­—ä¸²ï¼Œä¾‹ï¼šsubtopics.1.subsubtopics.3
            is_topic_level: True ä»£è¡¨ã€Œæœ€å¤–å±¤ä¸»é¡Œã€é‚£ä¸€å±¤ï¼›å…¶è·¯å¾‘ä¸æ‡‰å†è¢«åŠ é€² path
            """

            if not isinstance(node, dict):
                return

            # åˆ¤æ–·é€™ä¸€å±¤æ˜¯å¦ç‚ºã€Œä¸»é¡Œå±¤ã€ï¼ˆæœ€å¤–å±¤ï¼Œé€šå¸¸åŒæ™‚æ“æœ‰ title èˆ‡ subtopicsï¼‰
            current_is_topic = is_topic_level

            # å…ˆè™•ç†æœ¬å±¤çš„ sql_textï¼ˆè‹¥æœ‰ï¼‰
            if "sql_text" in node:
                raw_sql = node["sql_text"]
                # çµ±ä¸€è½‰æˆ list æ–¹ä¾¿è™•ç†
                raw_sql = [raw_sql] if isinstance(raw_sql, str) else raw_sql

                if isinstance(raw_sql, list):
                    for idx, sql in enumerate(raw_sql):
                        if isinstance(sql, str) and sql.strip():

                            logger.info(
                                "[SQL] path=%s | title=%s | sql=%s...",
                                path.lstrip("."), node.get("title", ""), sql.strip()[:50]
                            )

                            queries.append(
                                {
                                    "question": sql.strip(),
                                    "title": node.get("title", ""),
                                    "path": path.lstrip("."),   # å»æ‰å‰å° '.' ä»¥å…å¾ŒçºŒæ¯”å°å‡ºéŒ¯
                                    "index": idx,
                                }
                            )

            # ç¹¼çºŒèµ°è¨ªå­ç¯€é»
            for key, value in node.items():
                # å…©å€‹å›ºå®šçš„å·¢ç‹€éµï¼šsubtopics / subsubtopicsï¼ˆä¸€å®šæ˜¯ listï¼‰
                if key in ("subtopics", "subsubtopics") and isinstance(value, list):
                    for idx, item in enumerate(value):
                        # åŠ å…¥ç›®å‰ç´¢å¼•ï¼Œç¢ºä¿ path = subtopics.<n>[.subsubtopics.<m>]
                        next_path = f"{path}.{key}.{idx}" if path else f"{key}.{idx}"
                        traverse(item, next_path, False)

                # å…¶é¤˜ä¸€èˆ¬ dict
                elif isinstance(value, dict):
                    next_path = path if current_is_topic else (f"{path}.{key}" if path else key)
                    traverse(value, next_path, False)

                # list ä½†å…ƒç´ å¯èƒ½æ˜¯ dict
                elif isinstance(value, list):
                    for item in value:
                        if isinstance(item, dict):
                            next_path = path if current_is_topic else (f"{path}.{key}" if path else key)
                            traverse(item, next_path, False)

        # é‡å°æ¯å€‹ã€Œä¸»é¡Œã€å€‹åˆ¥å•Ÿå‹•ä¸€æ¬¡éè¿´
        for topic_dict in output_format.values():
            traverse(topic_dict, "", True)
        
        return queries


    def get_sql_input(self, info: CompanyInfo) -> OutputFormat:

        input_company = info.company
        input_brand = info.brand
        input_product = info.product
        product_category = info.product_category
        input_target_title = info.target_title

        
        input_date = "2025å¹´4æœˆ"
        
        output_format = {
            "å¸‚å ´æ¦‚æ³èˆ‡è¶¨å‹¢": {
                "title": "å¸‚å ´æ¦‚æ³èˆ‡è¶¨å‹¢",
                "subtopics": [
                    {
                        "title": "ç”¢æ¥­è¦æ¨¡èˆ‡æˆé•·",
                        "subsubtopics": [
                            {
                                "title": "å°ç£å¸‚å ´è¦æ¨¡èˆ‡æˆé•·",
                                "sql_text": [""]
                            },
                            # {
                            #     "title": "ç”¢å“é¡å‹æ¼”é€²",
                            #     "sql_text": [""]
                            # },
                            # {
                            #     "title": "å¹´åº¦éŠ·å”®è®ŠåŒ–",
                            #     "sql_text": [""]
                            # },
                            # {
                            #     "title": "é©…å‹•å› ç´ èˆ‡æœªä¾†å±•æœ›",
                            #     "sql_text": [""]
                            # }
                        ]
                    },
                    {
                        "title": "ä¸»å°å“ç‰Œåˆ†æ",
                        "subsubtopics": [
                            {
                                "title": "ä¸»å°å“ç‰ŒéŠ·å”®æ¦‚æ³",
                                "sql_text": [f"""
                                {input_date}éŠ·å”®{input_brand} {input_product}å‰10åçš„å“ç‰Œï¼Œ
                                    1.è«‹æ‰¾å‡ºèˆ‡ {input_brand} åœ¨ {input_product} å¸‚å ´çš„ä¸»è¦ç«¶çˆ­å“ç‰Œï¼Œè¦æ±‚ï¼š
                                    1.åˆ—å‡º 10 å€‹ç›´æ¥ç«¶çˆ­å°æ‰‹
                                    2.åŒ…å«åœ‹éš›çŸ¥åå“ç‰Œå’Œæœ¬åœŸå“ç‰Œ
                                    3.ç¢ºä¿é€™äº›å“ç‰Œéƒ½æœ‰ç”Ÿç”¢é¡ä¼¼{input_product}çš„ç”¢å“
                                2.è«‹æ’°å¯«ä¸€å€‹ AWS Athena SQL æŸ¥è©¢ï¼Œç”¨æ–¼æ¯”è¼ƒå„å“ç‰Œé–“çš„éŠ·å”®é¡ï¼Œè¦æ±‚
                                    1.ä½¿ç”¨ CASE WHEN èªå¥ä¾†åˆ†é¡å“ç‰Œ
                                    2.ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå–å“ç‰Œåç¨±
                                    3.è¨ˆç®—æ¯å€‹ç«¶çˆ­å“ç‰Œçš„ç¸½éŠ·å”®é¡
                                    4.å°‡{input_brand}å–®ç¨æ­¸é¡
                                    5.éç«¶çˆ­å“ç‰Œæ­¸é¡ç‚º "å…¶ä»–å“ç‰Œ"
                                    6.çµæœé©åˆç”¨æ–¼è£½ä½œåœ“é¤…åœ–ï¼Œåœ–ä¸éœ€è¦å…¶ä»–å“ç‰Œ
                                3. éŠ·å”®é¡æ˜¯ unit_price * quantity
                                è«‹æä¾›å®Œæ•´çš„ SQL æŸ¥è©¢èªå¥ï¼Œè¦ç¢ºä¿ Query è£¡é¢ä¸æœƒæœ‰ç‰¹æ®Šç¬¦è™Ÿæœƒå°è‡´ Query å¤±æ•—ï¼ŒQuery å‡ºä¾†ä¹‹å¾Œï¼Œå†æª¢æŸ¥ä¸€æ¬¡ Queryï¼Œç¢ºä¿å¯ä»¥ç›´æ¥åœ¨ AWS Athena ä¸­åŸ·è¡Œã€‚
                                """]
                            },
                            # {
                            #     "title": "åƒ¹æ ¼å¸¶åˆ†æ",
                            #     "sql_text": [""]
                            # },
                            # {
                            #     "title": "å¹³åƒ¹å¸¶å¸‚å ´æ¦‚æ³",
                            #     "sql_text": [f"""
                            #     {input_date}éŠ·å”®{input_brand} {input_product}å‰10åçš„å“ç‰Œï¼Œ
                            #         1.è«‹æ‰¾å‡ºèˆ‡ {input_brand} åœ¨ {input_product} å¸‚å ´çš„ä¸»è¦ç«¶çˆ­å“ç‰Œï¼Œè¦æ±‚ï¼š
                            #         1.åˆ—å‡º 5 å€‹ç›´æ¥ç«¶çˆ­å°æ‰‹å“ç‰Œå®šå‘æ˜¯å¹³åƒ¹å“ç‰Œ
                            #         2.åŒ…å«åœ‹éš›çŸ¥åå“ç‰Œå’Œæœ¬åœŸå“ç‰Œ
                            #         3.ç¢ºä¿é€™äº›å“ç‰Œéƒ½æœ‰ç”Ÿç”¢é¡ä¼¼{input_product}çš„ç”¢å“
                            #     2.è«‹æ’°å¯«ä¸€å€‹ AWS Athena SQL æŸ¥è©¢ï¼Œç”¨æ–¼æ¯”è¼ƒå„å“ç‰Œé–“çš„éŠ·å”®é¡ï¼Œè¦æ±‚
                            #         1.ä½¿ç”¨ CASE WHEN èªå¥ä¾†åˆ†é¡å“ç‰Œ
                            #         2.ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå–å“ç‰Œåç¨±
                            #         3.è¨ˆç®—æ¯å€‹ç«¶çˆ­å“ç‰Œçš„ç¸½éŠ·å”®é¡
                            #         4.å°‡{input_brand}å–®ç¨æ­¸é¡
                            #         5.éç«¶çˆ­å“ç‰Œæ­¸é¡ç‚º "å…¶ä»–å“ç‰Œ"
                            #         6.çµæœé©åˆç”¨æ–¼è£½ä½œåœ“é¤…åœ–
                            #     3. éŠ·å”®é¡æ˜¯ unit_price * quantity
                            #     è«‹æä¾›å®Œæ•´çš„ SQL æŸ¥è©¢èªå¥ï¼Œè¦ç¢ºä¿ Query è£¡é¢ä¸æœƒæœ‰ç‰¹æ®Šç¬¦è™Ÿæœƒå°è‡´ Query å¤±æ•—ï¼ŒQuery å‡ºä¾†ä¹‹å¾Œï¼Œå†æª¢æŸ¥ä¸€æ¬¡ Queryï¼Œç¢ºä¿å¯ä»¥ç›´æ¥åœ¨ AWS Athena ä¸­åŸ·è¡Œã€‚
                            #     """]
                            # },
                            # {
                            #     "title": "é«˜åƒ¹å¸¶å¸‚å ´æ¦‚æ³",
                            #     "sql_text": [f"""
                            #     {input_date}éŠ·å”®{input_brand} {input_product}å‰10åçš„å“ç‰Œï¼Œ
                            #         1.è«‹æ‰¾å‡ºèˆ‡ {input_brand} åœ¨ {input_product} å¸‚å ´çš„ä¸»è¦ç«¶çˆ­å“ç‰Œï¼Œè¦æ±‚ï¼š
                            #         1.åˆ—å‡º 5 å€‹ç›´æ¥ç«¶çˆ­å°æ‰‹å“ç‰Œå®šå‘æ˜¯é«˜ç«¯å“ç‰Œ
                            #         2.åŒ…å«åœ‹éš›çŸ¥åå“ç‰Œå’Œæœ¬åœŸå“ç‰Œ
                            #         3.ç¢ºä¿é€™äº›å“ç‰Œéƒ½æœ‰ç”Ÿç”¢é¡ä¼¼{input_product}çš„ç”¢å“
                            #     2.è«‹æ’°å¯«ä¸€å€‹ AWS Athena SQL æŸ¥è©¢ï¼Œç”¨æ–¼æ¯”è¼ƒå„å“ç‰Œé–“çš„éŠ·å”®é¡ï¼Œè¦æ±‚
                            #         1.ä½¿ç”¨ CASE WHEN èªå¥ä¾†åˆ†é¡å“ç‰Œ
                            #         2.ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå–å“ç‰Œåç¨±
                            #         3.è¨ˆç®—æ¯å€‹ç«¶çˆ­å“ç‰Œçš„ç¸½éŠ·å”®é¡
                            #         4.å°‡{input_brand}å–®ç¨æ­¸é¡
                            #         5.éç«¶çˆ­å“ç‰Œæ­¸é¡ç‚º "å…¶ä»–å“ç‰Œ"
                            #         6.çµæœé©åˆç”¨æ–¼è£½ä½œåœ“é¤…åœ–ï¼Œåœ–ä¸éœ€è¦å…¶ä»–å“ç‰Œ
                            #     3. éŠ·å”®é¡æ˜¯ unit_price * quantity
                            #     è«‹æä¾›å®Œæ•´çš„ SQL æŸ¥è©¢èªå¥ï¼Œè¦ç¢ºä¿ Query è£¡é¢ä¸æœƒæœ‰ç‰¹æ®Šç¬¦è™Ÿæœƒå°è‡´ Query å¤±æ•—ï¼ŒQuery å‡ºä¾†ä¹‹å¾Œï¼Œå†æª¢æŸ¥ä¸€æ¬¡ Queryï¼Œç¢ºä¿å¯ä»¥ç›´æ¥åœ¨ AWS Athena ä¸­åŸ·è¡Œã€‚
                            #     """]
                            # },
                            # {
                            #     "title": "åƒ¹æ ¼å¸¶çµæ§‹èˆ‡ç­–ç•¥å®šä½",
                            #     "sql_text": [""] #Table not ready
                            # },
                            # {
                            #     "title": "åƒ¹æ ¼å¸¶å¸‚ä½”è®ŠåŒ–è¶¨å‹¢",
                            #     "sql_text": [""]
                            # }
                        ]
                    },
                    {
                        "title": "æ¶ˆè²»è€…ç—›é»èˆ‡è²é‡",
                        "subsubtopics": [
                            {
                                "title": "ç—›é»åˆ†æ",
                                "sql_text": [""]
                            },
                            # {
                            #     "title": "æ­£é¢ç†±é»äº‹ä»¶",
                            #     "sql_text": [""]
                            # },
                            # {
                            #     "title": "è² é¢ç†±é»äº‹ä»¶",
                            #     "sql_text": [""]
                            # },
                            # {
                            #     "title": "è²é‡èˆ‡æƒ…ç·’è¶¨å‹¢",
                            #     "sql_text": [""]
                            # },
                            # {
                            #     "title": "ç—›é»è½‰åŒ–æ©Ÿæœƒ",
                            #     "sql_text": [""]
                            # }
                        ]
                    },
                    {
                        "title": "æœªä¾†æ”¿ç­–èˆ‡æ°¸çºŒè¶¨å‹¢",
                        "subsubtopics": [
                            {
                                "title": "åœ‹éš›æ”¿ç­–å‹•å‘",
                                "sql_text": [""]
                            },
                            # {
                            #     "title": "å°ç£æ”¿ç­–å‹•å‘",
                            #     "sql_text": [""]
                            # },
                            # {
                            #     "title": "ESG èˆ‡æ°¸çºŒè­°é¡Œ",
                            #     "sql_text": [""]
                            # }
                        ]
                    },
                    {
                        "title": "å¸‚å ´æ¦‚æ³èˆ‡è¶¨å‹¢ç¸½çµ",
                        "subsubtopics": [
                            {
                                "title": "å¸‚å ´æ¦‚æ³ç¸½çµ",
                                "sql_text": [""]
                            },
                            # {
                            #     "title": "ç‚ºä½•é€™äº›è®ŠåŒ–é‡è¦",
                            #     "sql_text": [""]
                            # },
                            # {
                            #     "title": "å“ç‰Œè©²å¦‚ä½•æ‡‰å°å¸‚å ´è®ŠåŒ–",
                            #     "sql_text": [""]
                            # }
                        ]
                    }
                ]
            },
            "å“ç‰Œå®šä½èˆ‡å½¢è±¡": {
                "title": "å“ç‰Œå®šä½èˆ‡å½¢è±¡",
                "subtopics": [
                    {
                        "title": "ç”¢æ¥­è¦æ¨¡èˆ‡æˆé•·",
                        "subsubtopics": [
                            {
                                "title": "å“ç‰Œåƒ¹æ ¼ç­–ç•¥",
                                "sql_text": [""]
                            },
                            # {
                            #     "title": "åŠŸèƒ½å®šä½åˆ†æ",
                            #     "sql_text": [""]
                            # }
                        ]
                    },
                    {
                        "title": "å“ç‰Œå½¢è±¡",
                        "subsubtopics": [
                            {
                                "title": "å“ç‰Œé—œéµå­—",
                                "sql_text": [""]
                            },
                            # {
                            #     "title": "å“ç‰Œè¦–è¦ºå…ƒç´ ",
                            #     "sql_text": [""]
                            # },
                            # {
                            #     "title": "å“ç‰Œæ¨™èª",
                            #     "sql_text": [""]
                            # }
                        ]
                    },
                    {
                        "title": "ç¨ç‰¹éŠ·å”®ä¸»å¼µï¼ˆUSPï¼‰",
                        "sql_text": [""]
                    }
                ]
            },
            "ç”¢å“åˆ†æ": {
                "title": "ç”¢å“åˆ†æ",
                "subtopics": [
                    {
                        "title": "ç”¢å“ç¨ç‰¹éŠ·å”®ä¸»å¼µï¼ˆUSPï¼‰",
                        "sql_text": [""]
                    },
                    {
                        "title": "ç”¢å“ä½¿ç”¨æƒ…å¢ƒ",
                        "sql_text": [""]
                    },
                    {
                        "title": "ç”¢å“éŠ·é‡",
                        # "sql_text": [""]
                        "sql_text": [f"""
                        {input_date} {input_product}éŠ·å”®é‡åœ¨ {input_brand} çš„å æ¯”ï¼Œ
                        1.è«‹æ’°å¯«ä¸€å€‹ AWS Athena SQL æŸ¥è©¢
                        2.éŠ·å”®é‡æ˜¯ sum(quantity)
                        3.çµæœé©åˆç”¨æ–¼è£½ä½œåœ“é¤…åœ–
                        è«‹æä¾›å®Œæ•´çš„ SQL æŸ¥è©¢èªå¥ï¼Œè¦ç¢ºä¿ Query è£¡é¢ä¸æœƒæœ‰ç‰¹æ®Šç¬¦è™Ÿæœƒå°è‡´ Query å¤±æ•—ï¼ŒQuery å‡ºä¾†ä¹‹å¾Œï¼Œå†æª¢æŸ¥ä¸€æ¬¡ Queryï¼Œç¢ºä¿å¯ä»¥ç›´æ¥åœ¨ AWS Athena ä¸­åŸ·è¡Œã€‚
                        """]
                    },
                    {
                        "title": "ç”¢å“éŠ·å”®é€šè·¯",
                        # "sql_text": [""]
                        "sql_text": [f"""
                        {input_date} {input_product}åœ¨storeName çš„è³¼è²·äººæ•¸(distinct vid)ï¼Œçµ¦å‰10å storeNameï¼Œå‰10åä¹‹å¾Œçš„ storeName çµ±ä¸€ç‚ºå…¶ä»–
                        1.ç¬¬ä¸€å€‹å­å¥å…ˆå»é™¤ storeName æ˜¯ NaN (storeName not like '%NaN%'),æ—¥æœŸå’Œ description like '%{input_brand}%'æˆ– '%{input_product}%'
                        2.çµæœé©åˆæ–¼è£½ä½œé•·æ¢åœ–
                        è«‹æä¾›å®Œæ•´çš„ SQL æŸ¥è©¢èªå¥ï¼Œè¦ç¢ºä¿ Query è£¡é¢ä¸æœƒæœ‰ç‰¹æ®Šç¬¦è™Ÿæœƒå°è‡´ Query å¤±æ•—ï¼ŒQuery å‡ºä¾†ä¹‹å¾Œï¼Œå†æª¢æŸ¥ä¸€æ¬¡ Queryï¼Œç¢ºä¿å¯ä»¥ç›´æ¥åœ¨ AWS Athena ä¸­åŸ·è¡Œã€‚
                        """]
                    }
                ]
            },
            "å—çœ¾æ´å¯Ÿèˆ‡æºé€šç­–ç•¥å»ºè­°": {
                "title": "å—çœ¾æ´å¯Ÿèˆ‡æºé€šç­–ç•¥å»ºè­°",
                "subtopics": [
                    {
                        "title": "å¸‚å ´å—çœ¾æ¦‚æ³",
                        "subsubtopics": [
                            {
                                "title": "äººå£å±¬æ€§",
                                # "sql_text": [""]
                                "sql_text": [f"""
                                æ‰¾å‡º{input_date}è³¼è²·{input_brand} {input_product}å¹´é½¡å’Œæ€§åˆ¥çš„ä½”æ¯”ï¼Œ
                                1.éœ€è¦ä¸é‡è¤‡çš„äººæ•¸(distinct vid)
                                2.å¹´é½¡åˆ†æˆ 18-24, 25-34, 35-44, 45-54, 55-64, 65+
                                3.æ€§åˆ¥åˆ†æˆ ç”·æ€§, å¥³æ€§
                                4.X è»¸æ˜¯å¹´é½¡ï¼ŒY è»¸æ˜¯ç™¾åˆ†æ¯”ä½”æ¯”ï¼Œç¶­åº¦æ˜¯æ€§åˆ¥
                                5.è«‹æ’°å¯«ä¸€å€‹ AWS Athena SQL æŸ¥è©¢ï¼Œä½¿ç”¨é•·æ¢åœ–é¡¯ç¤ºå¹´é½¡å’Œæ€§åˆ¥çš„ç™¾åˆ†æ¯”ä½”æ¯”
                                è«‹æä¾›å®Œæ•´çš„ SQL æŸ¥è©¢èªå¥ï¼Œè¦ç¢ºä¿ Query è£¡é¢ä¸æœƒæœ‰ç‰¹æ®Šç¬¦è™Ÿæœƒå°è‡´ Query å¤±æ•—ï¼ŒQuery å‡ºä¾†ä¹‹å¾Œï¼Œå†æª¢æŸ¥ä¸€æ¬¡ Queryï¼Œç¢ºä¿å¯ä»¥ç›´æ¥åœ¨ AWS Athena ä¸­åŸ·è¡Œã€‚
                               """]
                            },
                            # {
                            #     "title": "æ¶ˆè²»ç¿’æ…£",
                            #     # "sql_text": [""]
                            #     "sql_text": [f"""
                            #     æ‰¾å‡º{input_date}è³¼è²·{input_brand} {input_product}å¹´é½¡å’Œæ€§åˆ¥ç™¼ç¥¨å¹³å‡é‡‘é¡ï¼Œ
                            #     1.å¹´é½¡åˆ†æˆ 18-24, 25-34, 35-44, 45-54, 55-64, 65+
                            #     2.æ€§åˆ¥åˆ†æˆ ç”·æ€§, å¥³æ€§
                            #     3.ä¸€å¼µç™¼ç¥¨æœƒæœ‰å¾ˆå¤šçš„ç”¢å“ï¼Œæ¯å€‹ç”¢å“çš„ amountéƒ½æ˜¯ä¸€æ¨£ï¼Œä½†é€™æ˜¯ä¸å°ï¼Œè¦å¯«ä¸€å€‹å­å¥æ‰¾å‡º æ¯å€‹ inv_num çš„MAX(amount) AS invoice_amount
                            #     4.X è»¸æ˜¯å¹´é½¡ï¼ŒY è»¸æ˜¯ç™¼ç¥¨å¹³å‡é‡‘é¡ï¼Œç¶­åº¦æ˜¯æ€§åˆ¥
                            #     5.è«‹æ’°å¯«ä¸€å€‹ AWS Athena SQL æŸ¥è©¢ï¼Œä½¿ç”¨é•·æ¢åœ–é¡¯ç¤ºå¹´é½¡å’Œæ€§åˆ¥çš„ç™¼ç¥¨å¹³å‡é‡‘é¡
                            #     è«‹æä¾›å®Œæ•´çš„ SQL æŸ¥è©¢èªå¥ï¼Œè¦ç¢ºä¿ Query è£¡é¢ä¸æœƒæœ‰ç‰¹æ®Šç¬¦è™Ÿæœƒå°è‡´ Query å¤±æ•—ï¼ŒQuery å‡ºä¾†ä¹‹å¾Œï¼Œå†æª¢æŸ¥ä¸€æ¬¡ Queryï¼Œç¢ºä¿å¯ä»¥ç›´æ¥åœ¨ AWS Athena ä¸­åŸ·è¡Œã€‚
                            #     """]
                            # },
                            # {
                            #     "title": "è³¼è²·å‹•æ©Ÿ",
                            #     "sql_text": [""]
                            # }
                        ]
                    },
                    {
                        "title": "å•†å“ç›®æ¨™å—çœ¾åˆ†æ",
                        "subsubtopics": [
                            {
                                "title": "äººå£å±¬æ€§",
                                "sql_text": [""]
                            },
                            # {
                            #     "title": "æ¶ˆè²»ç¿’æ…£",
                            #     "sql_text": [""]
                            # },
                            # {
                            #     "title": "è³¼è²·å‹•æ©Ÿ",
                            #     "sql_text": [""]
                            # }
                        ]
                    },
                    {
                        "title": "ä»£è¡¨æ€§æ¶ˆè²»è€…è¼ªå»“ï¼ˆPersonaï¼‰",
                        "sql_text": [""]
                    }
                ]
            },
            "ç«¶å“åˆ†æ": {
                "title": "ç«¶å“åˆ†æ",
                "subtopics": [
                    {
                        "title": "ç«¶å“åƒ¹æ ¼èˆ‡åŠŸèƒ½å®šä½",
                        "subsubtopics": [
                            {
                                "title": "åƒ¹æ ¼ç­–ç•¥åˆ†æ",
                                "sql_text": [""]
                            },
                            # {
                            #     "title": "åŠŸèƒ½å®šä½æ¯”è¼ƒ",
                            #     "sql_text": [""]
                            # },
                            # {
                            #     "title": "ä½¿ç”¨æƒ…å¢ƒå°ç…§",
                            #     "sql_text": [""]
                            # }
                        ]
                    },
                    {
                        "title": "ç«¶å“éŠ·å”®ç‹€æ³åˆ†æ",
                        # "sql_text": [""]
                        "sql_text": [f"""
                        æ‰¾å‡º{input_date}éŠ·å”® / ç™¼ç¥¨å¼µæ•¸ / ä¸é‡è¤‡cid {input_brand} {input_product}å‰10åçš„å“ç‰Œï¼Œ
                        1.è«‹æ‰¾å‡ºèˆ‡{input_brand} {input_product}å¸‚å ´çš„ä¸»è¦ç«¶çˆ­å“ç‰Œï¼Œè¦æ±‚ï¼š
                          1.åˆ—å‡º 10 å€‹ç›´æ¥ç«¶çˆ­å°æ‰‹ï¼Œ
                          2.åŒ…å«åœ‹éš›çŸ¥åå“ç‰Œå’Œæœ¬åœŸå“ç‰Œ
                          3.ç¢ºä¿é€™äº›å“ç‰Œéƒ½æœ‰ç”Ÿç”¢é¡ä¼¼é‘½é«˜æ•ˆé˜²æ›¬éœ²NA 5Xç‰ˆçš„ç”¢å“
                        2.è«‹æ’°å¯«ä¸€å€‹ AWS Athena SQL æŸ¥è©¢ï¼Œç”¨æ–¼æ¯”è¼ƒå„å“ç‰Œé–“çš„éŠ·å”®é¡ï¼Œè¦æ±‚
                          1.ä½¿ç”¨ CASE WHEN èªå¥ä¾†åˆ†é¡å“ç‰Œ
                          2.ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå–å“ç‰Œåç¨±
                          3.è¨ˆç®—æ¯å€‹ç«¶çˆ­å“ç‰Œçš„ç¸½éŠ·å”®é¡
                          4.å°‡{input_brand}å–®ç¨æ­¸é¡
                          5.éç«¶çˆ­å“ç‰Œæ­¸é¡ç‚º "å…¶ä»–å“ç‰Œ"
                          6.çµæœé©åˆç”¨æ–¼è£½ä½œé•·æ¢åœ–ï¼Œåœ–ä¸éœ€è¦å…¶ä»–å“ç‰Œ
                        3. éŠ·å”®é¡æ˜¯ unit_price * quantity
                        4. ç™¼ç¥¨å¼µæ•¸æ˜¯ count(distinct inv_num)
                        5. ä¸é‡è¤‡cidæ˜¯ count(distinct vid)
                        6. çµæœé©åˆç”¨æ–¼è£½ä½œé•·æ¢åœ–ï¼Œåœ–ä¸éœ€è¦å…¶ä»–å“ç‰Œï¼Œx è»¸æ˜¯å“ç‰Œï¼Œy è»¸æ˜¯ç™¾åˆ†æ¯”ï¼Œç¶­åº¦æ˜¯éŠ·å”®ä½”æ¯”, ç™¼ç¥¨å¼µæ•¸, ä¸é‡è¤‡cid
                        7. åªéœ€è¦ä¸€å¼µåœ–ï¼Œåœ–çš„é¡è‰²è¦å€åˆ†éŠ·å”®ä½”æ¯”, ç™¼ç¥¨å¼µæ•¸, ä¸é‡è¤‡cid
                        è«‹æä¾›å®Œæ•´çš„ SQL æŸ¥è©¢èªå¥ï¼Œè¦ç¢ºä¿ Query è£¡é¢ä¸æœƒæœ‰ç‰¹æ®Šç¬¦è™Ÿæœƒå°è‡´ Query å¤±æ•—ï¼ŒQuery å‡ºä¾†ä¹‹å¾Œï¼Œå†æª¢æŸ¥ä¸€æ¬¡ Queryï¼Œç¢ºä¿å¯ä»¥ç›´æ¥åœ¨ AWS Athena ä¸­åŸ·è¡Œã€‚
                        """]
                    },
                    {
                        "title": "ä»£è¡¨é€šè·¯éŠ·é‡å°æ¯”",
                        "subsubtopics": [
                            {
                                "title": "é›»å•†å¹³å°éŠ·é‡å°æ¯”",
                                # "sql_text": [""]
                                "sql_text": [f"""
                                æ‰¾å‡º{input_date}éŠ·å”®é¡ {input_brand} {input_product}å‰10åçš„å“ç‰Œï¼Œå…ˆå¯«å‡ºä¸€å€‹å­—å¥æ‰¾å‡º storeName æ˜¯é›»å­å•†å‹™å¹³å°çš„æ¢ä»¶ï¼Œä¾‹å¦‚ MOMO, PChome, Yahoo, è¦çš®, è«‹æ ¹æ“šå¯¦éš›æƒ…æ³ä¿®æ”¹ï¼Œ
                                1.è«‹æ‰¾å‡ºèˆ‡{input_brand} {input_product}å¸‚å ´çš„ä¸»è¦ç«¶çˆ­å“ç‰Œï¼Œè¦æ±‚ï¼š
                                  1.åˆ—å‡º 10 å€‹ç›´æ¥ç«¶çˆ­å°æ‰‹ï¼Œ
                                  2.åŒ…å«åœ‹éš›çŸ¥åå“ç‰Œå’Œæœ¬åœŸå“ç‰Œ
                                  3.ç¢ºä¿é€™äº›å“ç‰Œéƒ½æœ‰ç”Ÿç”¢é¡ä¼¼{input_product}çš„ç”¢å“
                                2.è«‹æ’°å¯«ä¸€å€‹ AWS Athena SQL æŸ¥è©¢ï¼Œç”¨æ–¼æ¯”è¼ƒå„å“ç‰Œé–“çš„éŠ·å”®é¡ï¼Œè¦æ±‚
                                  1.ä½¿ç”¨ CASE WHEN èªå¥ä¾†åˆ†é¡å“ç‰Œ
                                  2.ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå–å“ç‰Œåç¨±
                                  3.è¨ˆç®—æ¯å€‹ç«¶çˆ­å“ç‰Œçš„ç¸½éŠ·å”®é¡
                                  4.å°‡{input_brand}å–®ç¨æ­¸é¡
                                  5.éç«¶çˆ­å“ç‰Œæ­¸é¡ç‚º "å…¶ä»–å“ç‰Œ"
                                  6.çµæœé©åˆç”¨æ–¼è£½ä½œé•·æ¢åœ–ï¼Œåœ–ä¸éœ€è¦å…¶ä»–å“ç‰Œ
                                3. éŠ·å”®é¡æ˜¯ unit_price * quantity
                                6. çµæœé©åˆç”¨æ–¼è£½ä½œé•·æ¢åœ–ï¼Œåœ–ä¸éœ€è¦å…¶ä»–å“ç‰Œï¼Œx è»¸æ˜¯storeNameï¼Œy è»¸æ˜¯éŠ·å”®é¡ï¼Œç¶­åº¦æ˜¯å“ç‰Œåç¨±(ä¸éœ€è¦å †ç–Š),
                                7. åªéœ€è¦ä¸€å¼µåœ–ï¼Œåœ–çš„é¡è‰²è¦å€åˆ†éŠ·å”®é¡
                                è«‹æä¾›å®Œæ•´çš„ SQL æŸ¥è©¢èªå¥ï¼Œè¦ç¢ºä¿ Query è£¡é¢ä¸æœƒæœ‰ç‰¹æ®Šç¬¦è™Ÿæœƒå°è‡´ Query å¤±æ•—ï¼ŒQuery å‡ºä¾†ä¹‹å¾Œï¼Œå†æª¢æŸ¥ä¸€æ¬¡ Queryï¼Œç¢ºä¿å¯ä»¥ç›´æ¥åœ¨ AWS Athena ä¸­åŸ·è¡Œã€‚
                                """]
                            },
                            # {
                            #     "title": "ç·šä¸‹é€šè·¯éŠ·é‡å°æ¯”",
                            #     # "sql_text": [""]
                            #     "sql_text": [f"""
                            #     æ‰¾å‡º{input_date}éŠ·å”®é¡ {input_brand} {input_product}å‰10åçš„å“ç‰Œ
                            #     1.å…ˆå¯«å‡ºä¸€å€‹å­—å¥æ’é™¤ storeName æ˜¯é›»å­å•†å‹™å¹³å°çš„æ¢ä»¶ï¼Œä¾‹å¦‚ MOMO, PChome, Yahoo, è¦çš®, è«‹æ ¹æ“šå¯¦éš›æƒ…æ³ä¿®æ”¹ï¼Œ
                            #     2.storeName æ˜¯ NaN (storeName not like '%NaN%') ä¹Ÿéœ€è¦æ’é™¤
                            #     3.åªéœ€è¦éŠ·å”®é¡å‰10åçš„storeName å’ŒéŠ·å”®é¡å‰5åçš„å“ç‰Œ
                            #     4.è«‹æ‰¾å‡ºèˆ‡{input_brand} {input_product}å¸‚å ´çš„ä¸»è¦ç«¶çˆ­å“ç‰Œï¼Œè¦æ±‚ï¼š
                            #       1.åˆ—å‡º 10 å€‹ç›´æ¥ç«¶çˆ­å°æ‰‹ï¼Œ
                            #       2.åŒ…å«åœ‹éš›çŸ¥åå“ç‰Œå’Œæœ¬åœŸå“ç‰Œ
                            #       3.ç¢ºä¿é€™äº›å“ç‰Œéƒ½æœ‰ç”Ÿç”¢é¡ä¼¼{input_product}çš„ç”¢å“
                            #     5.è«‹æ’°å¯«ä¸€å€‹ AWS Athena SQL æŸ¥è©¢ï¼Œç”¨æ–¼æ¯”è¼ƒå„å“ç‰Œé–“çš„éŠ·å”®é¡ï¼Œè¦æ±‚
                            #       1.ä½¿ç”¨ CASE WHEN èªå¥ä¾†åˆ†é¡å“ç‰Œ
                            #       2.ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå–å“ç‰Œåç¨±
                            #       3.è¨ˆç®—æ¯å€‹ç«¶çˆ­å“ç‰Œçš„ç¸½éŠ·å”®é¡
                            #       4.å°‡{input_brand}å–®ç¨æ­¸é¡
                            #       5.éç«¶çˆ­å“ç‰Œæ­¸é¡ç‚º "å…¶ä»–å“ç‰Œ"
                            #       6.çµæœé©åˆç”¨æ–¼è£½ä½œé•·æ¢åœ–ï¼Œåœ–ä¸éœ€è¦å…¶ä»–å“ç‰Œ
                            #     6. éŠ·å”®é¡æ˜¯ unit_price * quantity
                            #     7. çµæœé©åˆç”¨æ–¼è£½ä½œé•·æ¢åœ–ï¼Œåœ–ä¸éœ€è¦å…¶ä»–å“ç‰Œï¼Œx è»¸æ˜¯storeNameï¼Œy è»¸æ˜¯éŠ·å”®é¡ï¼Œç¶­åº¦æ˜¯å“ç‰Œåç¨±,
                            #     8. åªéœ€è¦ä¸€å¼µåœ–ï¼Œåœ–çš„é¡è‰²è¦å€åˆ†éŠ·å”®ä½”æ¯”
                            #     è«‹æä¾›å®Œæ•´çš„ SQL æŸ¥è©¢èªå¥ï¼Œè¦ç¢ºä¿ Query è£¡é¢ä¸æœƒæœ‰ç‰¹æ®Šç¬¦è™Ÿæœƒå°è‡´ Query å¤±æ•—ï¼ŒQuery å‡ºä¾†ä¹‹å¾Œï¼Œå†æª¢æŸ¥ä¸€æ¬¡ Queryï¼Œç¢ºä¿å¯ä»¥ç›´æ¥åœ¨ AWS Athena ä¸­åŸ·è¡Œã€‚
                            #     """]
                            # }
                        ]
                    },
                    {
                        "title": "ç«¶å“ç¨ç‰¹éŠ·å”®ä¸»å¼µï¼ˆUSPï¼‰",
                        "sql_text": [""]
                    },
                    {
                        "title": "èˆ‡ç«¶å“ä¹‹å„ªåŠ£åˆ†æ",
                        "sql_text": [""]
                    }
                ]
            }
        }

        # å¦‚æœæŒ‡å®šäº† input_target_titleï¼Œåªè¿”å›è©²ä¸»é¡Œ
        if input_target_title and input_target_title in output_format:
            return {input_target_title: output_format[input_target_title]}
        
        return output_format
    
    def upload_chart_to_s3(
        self,
        uu_id: str,
        idx: int,
        file_bytes: bytes,
        *,
        fmt: str = "html",  # 'html' æˆ– 'png'
    ) -> str:
        """
        å°‡åœ–è¡¨ï¼ˆHTML / PNGï¼‰ä¸Šå‚³åˆ° S3  
        - fmt='html' â†’ vanna/<id>/fig_<n>.html , ContentType=text/html  
        - fmt='png'  â†’ vanna/<id>/fig_<n>.png  , ContentType=image/png  
        å¤±æ•—è‡ªå‹•é‡è©¦ `S3_MAX_RETRY` æ¬¡ï¼›æˆåŠŸå›å‚³å…¬é–‹ URL
        """
        if fmt not in {"html", "png"}:
            raise ValueError(f"Unsupported fmt: {fmt}")

        # ---------- 1. S3 key & MIME ----------
        ext_map = {"html": ("html", "text/html"), "png": ("png", "image/png")}
        ext, mime = ext_map[fmt]
        key = f"vanna/{uu_id}/fig_{idx}.{ext}"
        s3_client = self.conn.s3_client_fbmapping()

        # ---------- 2. put_object with retry ----------
        last_err: Optional[Exception] = None
        for attempt in range(S3_MAX_RETRY + 1):
            try:
                s3_client.put_object(
                    Bucket=self.s3_bucket,
                    Key=key,
                    Body=file_bytes,
                    ContentType=mime,
                )
                url = f"https://{self.s3_bucket}.s3.amazonaws.com/{key}"
                logger.info(
                    f"Uploaded {fmt.upper()} to S3 (try {attempt+1}/{S3_MAX_RETRY+1}): {key}"
                )
                return url
            except Exception as e:      # noqa: BLE001
                last_err = e
                logger.warning(f"S3 put_object å¤±æ•— (try {attempt+1}): {e}")
                time.sleep(S3_RETRY_SLEEP)
                # ---------- 3. å…¨éƒ¨å˜—è©¦å¤±æ•— ----------
                raise RuntimeError(f"S3 ä¸Šå‚³{fmt.upper()}å¤±æ•— ({S3_MAX_RETRY+1} attempts): {last_err}")

        
    def _verify_indices(self) -> None:
        """é©—è­‰å¿…è¦çš„ç´¢å¼•æ˜¯å¦å­˜åœ¨"""
        indices = [self.document_index, self.ddl_index, self.question_sql_index]
        for idx in indices:
            try:
                if not self.opensearch_client.indices.exists(index=idx):
                    logger.warning(f"Index {idx} does not exist")
                else:
                    logger.info(f"Index {idx} exists")
            except Exception as e:
                logger.error(f"Error checking index {idx}: {e}")
                raise ValidationError(f"Failed to check OpenSearch index {idx}: {e}")
    
    def set_athena_connection(self, run_sql_func: Callable[[str], pd.DataFrame]) -> None:
        """è¨­å®šAthenaé€£æ¥åŠSQLåŸ·è¡Œå‡½æ•¸"""
        self.run_sql = run_sql_func
        self.run_sql_is_set = True
        self.dialect = "AWS Athena SQL"
        logger.info("Athena connection set successfully")
    
    def add_documentation(self, documentation: str, **kwargs) -> str:
        """æ·»åŠ æ–‡æª”åˆ°æ–‡æª”ç´¢å¼•"""
        return self._index(self.document_index, {"doc": documentation}, **kwargs)

    def add_ddl(self, ddl: str, **kwargs) -> str:
        """æ·»åŠ DDLåˆ°DDLç´¢å¼•"""
        return self._index(self.ddl_index, {"ddl": ddl}, **kwargs)

    def add_question_sql(self, question: str, sql: str, **kwargs) -> str:
        """æ·»åŠ å•é¡Œå’ŒSQLåˆ°å•é¡Œç´¢å¼•"""
        return self._index(self.question_sql_index, {"question": question, "sql": sql}, **kwargs)

    def _index(self, index: str, body: Dict[str, Any], **kwargs) -> str:
        """å‘ç´¢å¼•åŠ æ–‡æª”"""
        try:
            resp = self.opensearch_client.index(index=index, body=body, **kwargs)
            return resp["_id"]
        except Exception as e:
            logger.error(f"Indexing to {index} failed: {e}")
            raise ExternalAPIError(f"Failed to index to {index}: {e}")

    def get_related_ddl(self, question: str, **kwargs) -> List[str]:
        """ç²å–èˆ‡å•é¡Œç›¸é—œçš„DDL"""
        return self._search(self.ddl_index, "ddl", question, **kwargs)

    def get_related_documentation(self, question: str, **kwargs) -> List[str]:
        """ç²å–èˆ‡å•é¡Œç›¸é—œçš„æ–‡æª”"""
        return self._search(self.document_index, "doc", question, **kwargs)

    def get_similar_question_sql(self, question: str, **kwargs) -> List[Dict[str, str]]:
        """ç²å–èˆ‡å•é¡Œç›¸ä¼¼çš„å•é¡Œå’ŒSQL"""
        try:
            q = {"query": {"match": {"question": question}}}
            resp = self.opensearch_client.search(index=self.question_sql_index, body=q, **kwargs)
            return [
                {"question": h["_source"]["question"], "sql": h["_source"]["sql"]}
                for h in resp["hits"]["hits"]
            ]
        except Exception as e:
            logger.error(f"Search similar questions failed: {e}")
            return []

    def _search(self, index: str, field: str, query_str: str, **kwargs) -> List[Any]:
        """æœå°‹ç´¢å¼•ä¸­çš„æ–‡æª”"""
        try:
            q = {"query": {"match": {field: query_str}}}
            resp = self.opensearch_client.search(index=index, body=q, **kwargs)
            return [hit["_source"].get(field) for hit in resp["hits"]["hits"]]
        except Exception as e:
            logger.error(f"Search in {index} failed: {e}")
            return []