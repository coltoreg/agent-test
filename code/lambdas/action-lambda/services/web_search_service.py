from __future__ import annotations

import os
from collections.abc import Iterable, Sequence

from utils.logger import setup_logger
from utils.exceptions import ValidationError, ExternalAPIError
from utils.config_loader import load_industry_sites
from services.connections import Connections

logger = setup_logger(__name__)


class WebSearchService:
    """
    YAML â†’ includeâ•±exclude ç¶²åŸŸ â†’ çµ„åˆæŸ¥è©¢ â†’ å‘¼å« Perplexity
    """

    # é è¨­æ’é™¤ï¼ˆå¯ç”¨ç’°å¢ƒè®Šæ•¸è¦†å¯«ï¼‰
    DEFAULT_EXCLUDE = os.getenv(
        "EXCLUDE_SITES",
        "baidu.com, zhihu.com, weixin.qq.com"
    ).split(",")

    def __init__(self, cfg_path: str | None = None):
        self.conn = Connections()
        try:
            self._site_map = load_industry_sites(cfg_path)
        except Exception as e:
            logger.warning(f"Failed to load industry sites config: {e}")
            self._site_map = {}

    # -------------------------------------------------
    # PUBLIC API â€•â€• èˆ‡èˆŠç‰ˆä¿æŒç›¸åŒçš„ I/O ä»‹é¢
    # -------------------------------------------------
    def search_internet(
        self,
        query_text: str,
        *,
        industries: Sequence[str] | None = None,
        categories: Sequence[str] | None = None,
        extra_include: Sequence[str] | None = None,
        extra_exclude: Sequence[str] | None = None,
    ) -> dict:
        """
        ä¿ç•™èˆŠç‰ˆå‘¼å«æ–¹å¼ï¼š
            search_internet("ç”Ÿæˆå¼ AI")  âœ”ï¸

        äº¦æ”¯æ´é€²éšç©æ³•ï¼š
            search_internet(
                "2025 ç¾å¦å¸‚å ´è¶¨å‹¢",
                industries=["FMCG_ç¾å¦_é›»å•†ç”¢æ¥­"],
                categories=["ç¾å¦ç”¢æ¥­å‹•æ…‹"],
                extra_exclude=["reddit.com"],
            )
        """
        if not query_text:
            raise ValidationError("Query parameter is required.")

        include_sites = (
            set(self._collect_sites(industries, categories))
            | set(extra_include or [])
        )
        exclude_sites = set(self.DEFAULT_EXCLUDE) | set(extra_exclude or [])

        enhance_query = self._build_query(query_text, include_sites, exclude_sites)
        logger.info("ğŸ§© enhance_query = %s", enhance_query)

        messages = [
            {"role": "system", "content": "Be precise and concise."},
            {"role": "user", "content": enhance_query},
        ]

        try:
            client = self.conn.openai_client()
            response = client.chat.completions.create(
                model="sonar-pro",
                messages=messages,
                stream=False,
            )

            return {
                "query": enhance_query,
                "response": {
                    "answer": response.choices[0].message.content,
                    "sources": getattr(response, "citations", []),
                },
            }

        except ValidationError:
            raise
        except Exception as exc:
            logger.exception("Failed to perform internet search.")
            raise ExternalAPIError("Error performing internet search.") from exc

    # -------------------------------------------------
    # PRIVATE HELPERS
    # -------------------------------------------------
    def _collect_sites(
        self,
        industries: Sequence[str] | None,
        categories: Sequence[str] | None,
    ) -> list[str]:
        """æ ¹æ“š YAML é¸å‡ºæ¬² include çš„ç¶²åŸŸ"""
        sites: list[str] = []

        picked_industries = industries or self._site_map.keys()
        for ind in picked_industries:
            if ind not in self._site_map:
                logger.warning("Unknown industry: %s (ignored)", ind)
                continue

            picked_cates = categories or self._site_map[ind].keys()
            for cate in picked_cates:
                sites += self._site_map[ind].get(cate, [])

        return sites

    @staticmethod
    def _build_query(
        query_text: str,
        include_sites: Iterable[str],
        exclude_sites: Iterable[str],
    ) -> str:
        """site: èˆ‡ -site: å­å¥æ‹¼æ¥"""
        include_clause = " OR ".join(f"site:{s.strip()}" for s in include_sites)
        exclude_clause = " ".join(f"-site:{s.strip()}" for s in exclude_sites)
        return f"{query_text} {include_clause} {exclude_clause}".strip()